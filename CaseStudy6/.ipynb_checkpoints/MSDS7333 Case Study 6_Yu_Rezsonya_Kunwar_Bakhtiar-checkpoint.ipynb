{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> Using Statistics to Identify Spam </center></h1>\n",
    "<h3><center> Bin Yu, Nuoya Rezsonya, Yejur Singh Kunwar, Iram Bakhtiar</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question\n",
    "\n",
    "\n",
    "You have the option to choose one (and only one) of the following problems from the back of chapter 3 (<a href=\"http://rdatasciencecases.org/\">http://rdatasciencecases.org/</a>): 19, 20, or 21 instead of the case study mentioned at the end of module 6.8.\n",
    "\n",
    "- Q.19 Consider the other parameters that can be used to control the recursive partitioning\n",
    "    process. Read the documentation for them in the rpart.control() documentation. Also,\n",
    "    carry out an Internet search for more information on how to tweak the rpart() tuning\n",
    "    parameters. Experiment with values for these parameters. Do the trees that result make\n",
    "    sense with your understanding of how the parameters are used? Can you improve the\n",
    "    prediction using them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "\n",
    "1. [Abstract](#Abstract)\n",
    "2. [Introduction](#Introduction)\n",
    "3. [Background](#Background)\n",
    "4. [Methods](#Methods)\n",
    "5. [Results](#Results)\n",
    "6. [Conclusion](#Conclusion)\n",
    "7. [References](#References)\n",
    "8. [Appendix: Code](#Appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "\n",
    "[Back to Contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "At the very beginning of Internet, sending out commercial emails were not allowed. The first email spam was sent by Gary Thuerk in 1978 and 600 people received it. Email Spams has steadily grown since the early 1990s, and by 2014 spams has been estimated that it made up around 90% of email messages sent. Most of email spams are commercial in nature. Because of the expense of the spam is borne mostly by the person who receives it, it forms a perfect example of negative externality. \n",
    "Every Email service provider has used anti-spam techniques to filter and refuse spam based on the content of the email. Spam detection is a classification problem, either Spam or not. In this project, we will build our own Spam filter with the dataset that has been utilized in the book of Data Science in R: A Case Studies Approach to Computational Reasoning and Problem Solving [1] (“the book” in the followings).\n",
    "\n",
    "\n",
    "\n",
    "[Back to Contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "\n",
    "In order to build our own Spam filter, we use a dataset that has also been utilized in the book [1]. The dataset has more than 9000 emails that have been manually classified as Spam or not Spam by SpamAssassin[2] to make models. In the book [1], the dataset has been processed to add structure. We are using the same steps to clean up the data by regrouping them into header, body content and attachments (if any). This process will be automated by writing functions and then later being used on the whole dataset. Once the dataset has been processed, all unique words will be used to build a word dictionary which the frequency of words in Spam versus not Spam will be calculated. This process contributes to the establishment of the Spam detection classifier.\n",
    "\n",
    "We are also required to explore rpart library in R so that we can build an improved decision tree model and understand how each parameter affects the decision tree outcome by tuning each of them. In the followings, we will tune one parameter at a time, visualize and analyze the change in the tree outcome, then finish the project by tuning all parameters to provide a better decision tree model.\n",
    "\n",
    "[Back to Contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods\n",
    "\n",
    "**1. Classification Metrics**\n",
    "\n",
    "Before we jump into the parameter tuning and modelling, we have to decide the performance metrics to evaluate how well the model performs. As we mentioned above Spam detection is a classification problem, a good performance is that the model can get as few as false positive and false negative as possible. Common classification metrics are accuracy, precision, recall and F1 score. \n",
    "\n",
    "**Accuracy**: The ratio of number of correct predictions to the total number of predictions made. But it only works well when there are equal number of samples in each class. \n",
    "\n",
    "<center><img src=\"accuracy.png\"> <center>\n",
    "    \n",
    "**Precision**: The ratio of the number of correct positives to the number of positive results predicted by the model.\n",
    "\n",
    "<center><img src=\"precision.png\"> <center>\n",
    "    \n",
    "**Recall**: The ratio of the number of correct positives to the number of all samples that should have been tagged as positive)\n",
    "\n",
    "<center><img src=\"recall.png\"> <center>\n",
    "\t\n",
    "**F1 Score**: It is the harmonic mean between precision and recall. It is trying to find the balance between precision and recall. F1 score is a number that is between 0 and 1. It indicates how precise and robust our model is. A high F1 score should be preferred. \n",
    "\n",
    "<center><img src=\"f1.png\"><center> \n",
    "\n",
    "\n",
    "**2. Rpart Library**\n",
    "\n",
    "In this project we are using Rpart to create a decision tree. In R, the Rpart library (Recursive Partitioning and Regression Trees) is the algorithm implementation of the CART algorithm (Classification and Regression Trees). Decision trees use gini index as metric to evaluate the splits and determine features that have the greatest significance. A Gini score gives an idea of how good a split is by how mixed the classes are in the two groups created by the split. Gini score is calculated as[3] \n",
    "<center><img src=\"gini_score.png\">\n",
    "\n",
    "The rpart.control() is the control details of rpart algorithm which we have a list of various parameters that control aspects if rpart fit. There are 9 parameters that can be tuned to achieve different outcomes and we will talk about the most important ones that we have searched on the Internet. \n",
    "\n",
    "\n",
    "**1. Minsplit**\n",
    "\n",
    "The minimum number of observations in the parent node that must exist in a node in order for a split to be attempted. In other words, the number of observations in one child node.  For example, in R, this value is 20 by default, if there is any node that has less than 20 observations, it will be tagged as a terminal node and no split could happen. [4][5] Thermionically, if nothing is given to minsplit at all, not even that default value 20, the tree will go on forever till there is no observation left in a node to split. It is a parameter that prevents the algorithm from overfitting.  (Here I need some plot, something current cell 57 to show the relationship between minsplit and split). Maybe number of minsplits increases, number of splits decreases. \n",
    "\n",
    "**2. Minbucket**\n",
    "\n",
    "The smallest number of observations that are allowed in a terminal node. If a split decision breaks the data into a node with less than the given minbucket, it will not happen. It sounds very similar to minsplit. While minsplit informs the algorithm the number of observations the split could happen, the minbucket tells when to tag a node as terminal node. There is a relationship between minsplit and minbucket that If only one of minbucket or minsplit is specified, the code either sets minsplit to minbucket*3 or minbucket to minsplit/3, as appropriate [4][5]. Again, this parameter is just like minsplit, it prevents the algorithm from overfitting by limiting the number of child nodes that can exist in a tree. (I also need some plot for this part)\n",
    "\n",
    "**3. Cp**\n",
    "\n",
    "Complexity parameter is a stopping parameter. It speeds up the search for splits since it locates the splits that do not meet up with the criteria. The complexity parameter (cp) in rpart is the minimum improvement in the model needed at each node. It’s based on the cost complexity of the model defined as\n",
    "<center><img src=\"cp.png\">\n",
    "    \n",
    "It adds up the misclassification at every terminal node in a tree. Then it multiplies the number of the splits with a penalty term lamda. After this, add it to the total misclassification. This lamda is achieved by cross-validation. In R, if we use printcp(), it will show a scaled version of lamda over the misclassification rate of overall data[6]. Therefore, a smaller value will make the tree more complex. A max value is 1 and it creates a tree with zero splits. (plots needed)\n",
    "\n",
    "**4. maxdepth**\n",
    "\n",
    "It is used to set the maximum depth of any node of the final tree. In other words, it tells the algorithm, how many levels from a root node it can go down. For example, if we have set the maxdepth as 2, the tree can go down at most two levels. (plots needed) Therefore, finding the balance of this value is needed. If a low maxdepth value is given to the algorithm, the tree will be relatively shallow and only identify the features that have greatest impact on the model. On the other hand, if a large value is given, the tree will be improved till the point that the tree will go too long and has overfitting problem. (plots needed to show the concept)\n",
    "\n",
    "**5. xval**\n",
    "\n",
    "This parameter is simply the number of cross validations we need to perform on the dataset. Cross validation is always preferred in any data science project. It is a great way to train the model on several datasets partitioned into k-folds and then test it on the test set. This process contributes to improve the model performance. Normally it is a value between 5 and 10, although we use 10 folds valuation most of the time.\n",
    "\n",
    "\n",
    "[Back to Contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "\n",
    "[Back to Contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "[Back to Contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. https://www.rdocumentation.org/packages/rpart/versions/4.1-15/topics/rpart.control\n",
    "2. https://www.rdocumentation.org/packages/rpart/versions/4.1-15/topics/rpart\n",
    "3. https://www.gormanalysis.com/blog/decision-trees-in-r-using-rpart/\n",
    "4. https://www.datanovia.com/en/blog/ggplot-title-subtitle-and-caption/\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[Back to Contents](#Contents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "\n",
    "[Back to Contents](#Contents)\n",
    "\n",
    "## Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install.packages(\"tm\", dependencies=TRUE, repos='http://cran.rstudio.com/')\n",
    "# above may not working very well, you can use conda to install in your jupyter environment.\n",
    "# conda install r-tm\n",
    "# install.packages(\"rpart\", dependencies=TRUE, repos='http://cran.rstudio.com/')\n",
    "# install.packages(\"rpart.plot\", dependencies=TRUE, repos='http://cran.rstudio.com/')\n",
    "# install.packages(\"MLmetrics\", dependencies=TRUE, repos='http://cran.rstudio.com/')\n",
    "# install.packages(\"naivebayes\", dependencies=TRUE, repos='http://cran.rstudio.com/')\n",
    "# install.packages(\"xgboost\", dependencies=TRUE, repos='http://cran.rstudio.com/')\n",
    "# install.packages(\"Rcpp\", dependencies=TRUE, repos='http://cran.rstudio.com/')\n",
    "# install.packages(\"plotly\", dependencies=TRUE, repos='http://cran.rstudio.com/')\n",
    "# install.packages(\"R.utils\", dependencies=TRUE, repos='http://cran.rstudio.com/')\n",
    "# install.packages(\"readtext\", dependencies=TRUE, repos='http://cran.rstudio.com/')\n",
    "# install.packages(\"filesstrings\", dependencies=TRUE, repos='http://cran.rstudio.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in library(NLP): there is no package called 'NLP'\n",
     "output_type": "error",
     "traceback": [
      "Error in library(NLP): there is no package called 'NLP'\nTraceback:\n",
      "1. library(NLP)",
      "2. stop(txt, domain = NA)"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "\n",
    "library(NLP)\n",
    "library(tm)\n",
    "library(RColorBrewer)\n",
    "library(rpart)\n",
    "library(rpart.plot)\n",
    "library(RColorBrewer)\n",
    "library(caret)\n",
    "library(MLmetrics)\n",
    "library(naivebayes)\n",
    "library(e1071)\n",
    "library(randomForest)\n",
    "library(xgboost)\n",
    "library(R.utils)\n",
    "library(readtext)\n",
    "library(filesstrings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data from website (Don't need to run as we have the data alrady)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# web site to download the spam messages\n",
    "url = 'https://spamassassin.apache.org/old/publiccorpus/'\n",
    "# spam path to save the files\n",
    "spamPath = \"./SpamAssassinMessages/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the zip file list\n",
    "files = c('20030228_easy_ham.tar.bz2','20030228_hard_ham.tar.bz2','20030228_easy_ham_2.tar.bz2'\n",
    "          ,'20030228_spam.tar.bz2','20050311_spam_2.tar.bz2'\n",
    "          # t match with the book\n",
    "         ,'20021010_easy_ham.tar.bz2','20021010_hard_ham.tar.bz2','20021010_spam.tar.bz2','20030228_spam_2.tar.bz2'\n",
    "         )\n",
    "for (file in files){    \n",
    "    inputfile = paste(url,file,sep = \"\")\n",
    "    outputfile = paste(spamPath,file,sep = \"\")\n",
    "    print(inputfile)\n",
    "    download.file(inputfile,outputfile)\n",
    "}\n",
    "# unzip the zip files to tar\n",
    "for (file in files){\n",
    "    inputfile = paste(spamPath,file,sep = \"\")\n",
    "    outputfile = gsub(\".bz2\", \"\", file)\n",
    "    outputfile = paste(spamPath,outputfile,sep = \"\")\n",
    "    print(outputfile)\n",
    "    bunzip2(inputfile, outputfile, remove = FALSE, skip = TRUE)\n",
    "    }\n",
    "# unzip tar files to folders\n",
    "for (file in files){\n",
    "    inputfile = gsub(\".bz2\", \"\", file)\n",
    "    inputfile = paste(spamPath,inputfile,sep = \"\")\n",
    "    ouputfolder = paste(spamPath,\"messages\",sep = \"\")\n",
    "    print(ouputfolder)\n",
    "    untar(inputfile, list=FALSE,exdir = ouputfolder) \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove a file which is not email format\n",
    "file.remove(paste(spamPath,\"/messages/spam/0000.7b1b73cf36cf9dbc3d64e3f2ee2b91f1\",sep = \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix the files have no \\n in the last row\n",
    "\n",
    "fixfiles = c(\"messages/hard_ham/00228.0eaef7857bbbf3ebf5edbbdae2b30493\"\n",
    "             ,\"messages/hard_ham/0231.7c6cc716ce3f3bfad7130dd3c8d7b072\"\n",
    "            ,\"messages/hard_ham/0250.7c6cc716ce3f3bfad7130dd3c8d7b072\"\n",
    "            ,\"messages/spam/00136.faa39d8e816c70f23b4bb8758d8a74f0\"\n",
    "             ,\"messages/spam/0143.260a940290dcb61f9327b224a368d4af\"\n",
    "            )\n",
    "for (file in fixfiles){\n",
    "    inputfile = paste(spamPath,file,sep = \"\")\n",
    "    #print(inputfile)\n",
    "    x = readtext(file=inputfile)\n",
    "    fileDesc = gsub(\"messages/hard_ham/\", \"\", file)\n",
    "    fileDesc = gsub(\"messages/spam/\", \"\", fileDesc)\n",
    "    #print (fileDesc)\n",
    "    f <- file(fileDesc, open=\"wb\")\n",
    "    write.table(x[\"text\"],file<-f,row.names=FALSE, col.names=FALSE,eol=\"\\n\",sep=\"\",quote=FALSE)\n",
    "    close(f)\n",
    "    targetfile=gsub(fileDesc, \"\", inputfile)\n",
    "    file.move(fileDesc,targetfile,overwrite = TRUE)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the files into data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  explor the source folder and get the file counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# explor the source folder and get the file counts\n",
    "spamPath = \"./SpamAssassinMessages/\"\n",
    "list.dirs(spamPath, full.names = FALSE)\n",
    "list.files(path = paste(spamPath, \"messages\", \n",
    "                        sep = .Platform$file.sep))\n",
    "\n",
    "list.files(path = paste(spamPath,'spam', sep=.Platform$file.sep))\n",
    "\n",
    "head(list.files(path = paste(spamPath, \"messages\", \"spam_2\",\n",
    "                             sep = .Platform$file.sep)))\n",
    "\n",
    "dirNames = list.files(path = paste(spamPath, \"messages\", \n",
    "                      sep = .Platform$file.sep))\n",
    "length(list.files(paste(spamPath, \"messages\", dirNames, \n",
    "                        sep = .Platform$file.sep)))\n",
    "\n",
    "sapply(paste(spamPath, \"messages\", dirNames, \n",
    "             sep = .Platform$file.sep), \n",
    "       function(dir) length(list.files(dir)) )\n",
    "\n",
    "fullDirNames = paste(spamPath, \"messages\", dirNames, \n",
    "                     sep = .Platform$file.sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Import first file and check the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split the email messages\n",
    "\n",
    "splitMessage = function(msg) {\n",
    "    \n",
    "    splitPoint = match(\"\", msg)\n",
    "         header = msg[1:(splitPoint)-1]\n",
    "         body = msg[ -(1:splitPoint) ]        \n",
    "  \n",
    "  return(list(header = header, body = body))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the boundary\n",
    "\n",
    "getBoundary = function(header) {\n",
    "  boundaryIdx = grep(\"boundary=\", header)\n",
    "  boundary = gsub('\"', \"\", header[boundaryIdx])\n",
    "  gsub(\".*boundary= *([^;]*);?.*\", \"\\\\1\", boundary)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to drop the email attachment\n",
    "\n",
    "dropAttach = function(body, boundary){\n",
    "  \n",
    "  bString = paste(\"--\", boundary, sep = \"\")\n",
    "  bStringLocs = which(bString == body)\n",
    "  \n",
    "  if (length(bStringLocs) <= 1) return(body)\n",
    "  \n",
    "  eString = paste(\"--\", boundary, \"--\", sep = \"\")\n",
    "  eStringLoc = which(eString == body)\n",
    "  if (length(eStringLoc) == 0) \n",
    "    return(body[ (bStringLocs[1] + 1) : (bStringLocs[2] - 1)])\n",
    "  \n",
    "  n = length(body)\n",
    "  if (eStringLoc < n) \n",
    "     return( body[ c( (bStringLocs[1] + 1) : (bStringLocs[2] - 1), \n",
    "                    ( (eStringLoc + 1) : n )) ] )\n",
    "  \n",
    "  return( body[ (bStringLocs[1] + 1) : (bStringLocs[2] - 1) ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get stop words list\n",
    "stopWords = stopwords()\n",
    "cleanSW = tolower(gsub(\"[[:punct:]0-9[:blank:]]+\", \" \", stopWords))\n",
    "SWords = unlist(strsplit(cleanSW, \"[[:blank:]]+\"))\n",
    "SWords = SWords[ nchar(SWords) > 1 ]\n",
    "stopWords = unique(SWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find the message word exclude the stop words\n",
    "findMsgWords = \n",
    "    function(msg, stopWords) {\n",
    "     if(is.null(msg))\n",
    "      return(character())\n",
    "\n",
    "     words = unique(unlist(strsplit(cleanText(msg), \"[[:blank:]\\t]+\")))\n",
    "\n",
    "     # drop empty and 1 letter words\n",
    "     words = words[ nchar(words) > 1]\n",
    "     words = words[ !( words %in% stopWords) ]\n",
    "     invisible(words)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean the \n",
    "cleanText = function(msg)   {\n",
    "  tolower(gsub(\"[[:punct:]0-9[:space:][:blank:]]+\", \" \", msg))\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to process all words in the files in given folder\n",
    "\n",
    "processAllWords = function(dirName, stopWords)\n",
    "{\n",
    "       # read all files in the directory\n",
    "  fileNames = list.files(dirName, full.names = TRUE)\n",
    "       # drop files that are not email, i.e., cmds\n",
    "  notEmail = grep(\"cmds$\", fileNames)\n",
    "  if ( length(notEmail) > 0) fileNames = fileNames[ - notEmail ]\n",
    "\n",
    "  messages = lapply(fileNames, readLines, encoding = \"latin1\")\n",
    "  \n",
    "       # split header and body\n",
    "  emailSplit = lapply(messages, splitMessage)\n",
    "       # put body and header in own lists\n",
    "  bodyList = lapply(emailSplit, function(msg) msg$body)\n",
    "  headerList = lapply(emailSplit, function(msg) msg$header)\n",
    "  rm(emailSplit)\n",
    "  \n",
    "       # determine which messages have attachments\n",
    "  hasAttach = sapply(headerList, function(header) {\n",
    "    CTloc = grep(\"Content-Type\", header)\n",
    "    if (length(CTloc) == 0) return(0)\n",
    "    multi = grep(\"multi\", tolower(header[CTloc])) \n",
    "    if (length(multi) == 0) return(0)\n",
    "    multi\n",
    "  })\n",
    "  \n",
    "  hasAttach = which(hasAttach > 0)\n",
    "  \n",
    "       # find boundary strings for messages with attachments\n",
    "  boundaries = sapply(headerList[hasAttach], getBoundary)\n",
    "  \n",
    "       # drop attachments from message body\n",
    "  bodyList[hasAttach] = mapply(dropAttach, bodyList[hasAttach], \n",
    "                               boundaries, SIMPLIFY = FALSE)\n",
    "  \n",
    "       # extract words from body\n",
    "  msgWordsList = lapply(bodyList, findMsgWords, stopWords)\n",
    "  \n",
    "  invisible(msgWordsList)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call processAllWords function to import and clean the emails into a data frame\n",
    "msgWordsList = lapply(fullDirNames, processAllWords, stopWords = stopWords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of messages count\n",
    "numMsgs = sapply(msgWordsList, length)\n",
    "numMsgs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isSpam = rep(c(FALSE, FALSE, FALSE, TRUE, TRUE), numMsgs)\n",
    "msgWordsList = unlist(msgWordsList, recursive = FALSE)\n",
    "\n",
    "numEmail = length(isSpam)\n",
    "numSpam = sum(isSpam)\n",
    "numHam = numEmail - numSpam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# build training set and test set\n",
    "set.seed(418910)\n",
    "\n",
    "testSpamIdx = sample(numSpam, size = floor(numSpam/3))\n",
    "testHamIdx = sample(numHam, size = floor(numHam/3))\n",
    "\n",
    "testMsgWords = c((msgWordsList[isSpam])[testSpamIdx],\n",
    "                 (msgWordsList[!isSpam])[testHamIdx] )\n",
    "trainMsgWords = c((msgWordsList[isSpam])[ - testSpamIdx], \n",
    "                  (msgWordsList[!isSpam])[ - testHamIdx])\n",
    "\n",
    "testIsSpam = rep(c(TRUE, FALSE), \n",
    "                 c(length(testSpamIdx), length(testHamIdx)))\n",
    "trainIsSpam = rep(c(TRUE, FALSE), \n",
    "                 c(numSpam - length(testSpamIdx), \n",
    "                   numHam - length(testHamIdx)))\n",
    "\n",
    "bow = unique(unlist(trainMsgWords))\n",
    "\n",
    "length(bow)\n",
    "\n",
    "spamWordCounts = rep(0, length(bow))\n",
    "\n",
    "names(spamWordCounts) = bow\n",
    "\n",
    "tmp = lapply(trainMsgWords[trainIsSpam], unique)\n",
    "tt = table( unlist(tmp) )\n",
    "spamWordCounts[ names(tt) ] = tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build the word table\n",
    "computeFreqs =\n",
    "function(wordsList, spam, bow = unique(unlist(wordsList)))\n",
    "{\n",
    "   # create a matrix for spam, ham, and log odds\n",
    "  wordTable = matrix(0.5, nrow = 4, ncol = length(bow), \n",
    "                     dimnames = list(c(\"spam\", \"ham\", \n",
    "                                        \"presentLogOdds\", \n",
    "                                        \"absentLogOdds\"),  bow))\n",
    "\n",
    "   # For each spam message, add 1 to counts for words in message\n",
    "  counts.spam = table(unlist(lapply(wordsList[spam], unique)))\n",
    "  wordTable[\"spam\", names(counts.spam)] = counts.spam + .5\n",
    "\n",
    "   # Similarly for ham messages\n",
    "  counts.ham = table(unlist(lapply(wordsList[!spam], unique)))  \n",
    "  wordTable[\"ham\", names(counts.ham)] = counts.ham + .5  \n",
    "\n",
    "\n",
    "   # Find the total number of spam and ham\n",
    "  numSpam = sum(spam)\n",
    "  numHam = length(spam) - numSpam\n",
    "\n",
    "   # Prob(word|spam) and Prob(word | ham)\n",
    "  wordTable[\"spam\", ] = wordTable[\"spam\", ]/(numSpam + .5)\n",
    "  wordTable[\"ham\", ] = wordTable[\"ham\", ]/(numHam + .5)\n",
    "  \n",
    "   # log odds\n",
    "  wordTable[\"presentLogOdds\", ] = \n",
    "     log(wordTable[\"spam\",]) - log(wordTable[\"ham\", ])\n",
    "  wordTable[\"absentLogOdds\", ] = \n",
    "     log((1 - wordTable[\"spam\", ])) - log((1 -wordTable[\"ham\", ]))\n",
    "\n",
    "  invisible(wordTable)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build traning table and classify the new messages\n",
    "trainTable = computeFreqs(trainMsgWords, trainIsSpam)\n",
    "\n",
    "newMsg = testMsgWords[[1]]\n",
    "\n",
    "newMsg = newMsg[!is.na(match(newMsg, colnames(trainTable)))]\n",
    "\n",
    "present = colnames(trainTable) %in% newMsg\n",
    "\n",
    "sum(trainTable[\"presentLogOdds\", present]) + \n",
    "  sum(trainTable[\"absentLogOdds\", !present])\n",
    "\n",
    "newMsg = testMsgWords[[ which(!testIsSpam)[1] ]]\n",
    "newMsg = newMsg[!is.na(match(newMsg, colnames(trainTable)))]\n",
    "present = (colnames(trainTable) %in% newMsg)\n",
    "sum(trainTable[\"presentLogOdds\", present]) + \n",
    "     sum(trainTable[\"absentLogOdds\", !present])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We place this simple code into a function so that we can calculate the log likelihood\n",
    "# ratio (LLR) for all of the test messages. \n",
    "computeMsgLLR = function(words, freqTable) \n",
    "{\n",
    "       # Discards words not in training data.\n",
    "  words = words[!is.na(match(words, colnames(freqTable)))]\n",
    "\n",
    "       # Find which words are present\n",
    "  present = colnames(freqTable) %in% words\n",
    "\n",
    "  sum(freqTable[\"presentLogOdds\", present]) +\n",
    "    sum(freqTable[\"absentLogOdds\", !present])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply computedMsgLLR to each message\n",
    "testLLR = sapply(testMsgWords, computeMsgLLR, trainTable)\n",
    "\n",
    "tapply(testLLR, testIsSpam, summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf(\"SP_Boxplot.pdf\", width = 6, height = 6)\n",
    "spamLab = c(\"ham\", \"spam\")[1 + testIsSpam]\n",
    "boxplot(testLLR ~ spamLab, ylab = \"Log Likelihood Ratio\",\n",
    "        main = \"Figure 1. Log Likelihood Ratio for Randomly Chosen Test Messages\",\n",
    "#         sub =\"Figure 1. Log Likelihood Ratio for Randomly Chosen Test Messages.The log likelihood ratio,\n",
    "# log(P( spam | message content)/P( ham | message content)), for 3116 test messages was\n",
    "# computed using a naïve Bayes approximation based on word frequencies found in manually\n",
    "# classified training data. The test messages are grouped according to whether they are spam\n",
    "# or ham. Notice most ham messages have values well below 0 and nearly all spam values are\n",
    "# above 0.\",\n",
    "        ylim=c(-500, 500))\n",
    "#dev.off()\n",
    "dev.copy(png,'Figure_1_SP_Boxplot.png')\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# function for type I error rates\n",
    "typeIErrorRates = \n",
    "function(llrVals, isSpam) \n",
    "{\n",
    "  o = order(llrVals)\n",
    "  llrVals =  llrVals[o]\n",
    "  isSpam = isSpam[o]\n",
    "\n",
    "  idx = which(!isSpam)\n",
    "  N = length(idx)\n",
    "  list(error = (N:1)/N, values = llrVals[idx])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for type II error rate\n",
    "typeIIErrorRates = function(llrVals, isSpam) {\n",
    "    \n",
    "  o = order(llrVals)\n",
    "  llrVals =  llrVals[o]\n",
    "  isSpam = isSpam[o]\n",
    "    \n",
    "    \n",
    "  idx = which(isSpam)\n",
    "  N = length(idx)\n",
    "  list(error = (1:(N))/N, values = llrVals[idx])\n",
    "  }  \n",
    "\n",
    "xI = typeIErrorRates(testLLR, testIsSpam)\n",
    "xII = typeIIErrorRates(testLLR, testIsSpam)\n",
    "tau01 = round(min(xI$values[xI$error <= 0.01]))\n",
    "t2 = max(xII$error[ xII$values < tau01 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf(\"LinePlotTypeI+IIErrors.pdf\", width = 8, height = 6)\n",
    "\n",
    "#library(RColorBrewer)\n",
    "cols = brewer.pal(9, \"Set1\")[c(3, 4, 5)]\n",
    "plot(xII$error ~ xII$values,  type = \"l\", col = cols[1], lwd = 3,\n",
    "     xlim = c(-300, 250), ylim = c(0, 1),\n",
    "     xlab = \"Log Likelihood Ratio Values\",\n",
    "      main = \"Figure 2: Comparison of Type I and II Error Rates.\",\n",
    "     ylab=\"Error Rate\")\n",
    "points(xI$error ~ xI$values, type = \"l\", col = cols[2], lwd = 3)\n",
    "legend(x = 50, y = 0.4, fill = c(cols[2], cols[1]),\n",
    "       legend = c(\"Classify Ham as Spam\", \n",
    "                  \"Classify Spam as Ham\"), cex = 0.8,\n",
    "       bty = \"n\")\n",
    "abline(h=0.01, col =\"grey\", lwd = 3, lty = 2)\n",
    "text(-250, 0.05, pos = 4, \"Type I Error = 0.01\", col = cols[2])\n",
    "\n",
    "mtext(tau01, side = 1, line = 0.5, at = tau01, col = cols[3])\n",
    "segments(x0 = tau01, y0 = -.50, x1 = tau01, y1 = t2, \n",
    "         lwd = 2, col = \"grey\")\n",
    "text(tau01 + 20, 0.05, pos = 4,\n",
    "     paste(\"Type II Error = \", round(t2, digits = 2)), \n",
    "     col = cols[1])\n",
    "\n",
    "dev.copy(png,'Figure_2_LinePlotTypeI+IIErrors.png')\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# five folds\n",
    "\n",
    "k= 5\n",
    "numTrain = length(trainMsgWords)\n",
    "partK = sample(numTrain)\n",
    "tot = k * floor(numTrain/k)\n",
    "partK = matrix(partK[1:tot], ncol = k)\n",
    "\n",
    "testFoldOdds = NULL\n",
    "for (i in 1:k) {\n",
    "  foldIdx = partK[ , i]\n",
    "  trainTabFold = computeFreqs(trainMsgWords[-foldIdx], trainIsSpam[-foldIdx])\n",
    "  testFoldOdds = c(testFoldOdds, \n",
    "               sapply(trainMsgWords[ foldIdx ], computeMsgLLR, trainTabFold))\n",
    "}\n",
    "\n",
    "testFoldSpam = NULL\n",
    "for (i in 1:k) {\n",
    "  foldIdx = partK[ , i]\n",
    "  testFoldSpam = c(testFoldSpam, trainIsSpam[foldIdx])\n",
    "}\n",
    "\n",
    "xFoldI = typeIErrorRates(testFoldOdds, testFoldSpam)\n",
    "xFoldII = typeIIErrorRates(testFoldOdds, testFoldSpam)\n",
    "tauFoldI = round(min(xFoldI$values[xFoldI$error <= 0.01]))\n",
    "tFold2 = xFoldII$error[ xFoldII$values < tauFoldI ]\n",
    "\n",
    "smallNums = rep((1/2)^40, 2000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to process header\n",
    "processHeader = function(header)\n",
    "{\n",
    "       # modify the first line to create a key:value pair\n",
    "  header[1] = sub(\"^From\", \"Top-From:\", header[1])\n",
    "  \n",
    "  headerMat = read.dcf(textConnection(header), all = TRUE)\n",
    "  headerVec = unlist(headerMat)\n",
    "  \n",
    "  dupKeys = sapply(headerMat, function(x) length(unlist(x)))\n",
    "  names(headerVec) = rep(colnames(headerMat), dupKeys)\n",
    "  \n",
    "  return(headerVec)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to process attachment of the email\n",
    "\n",
    "processAttach = function(body, contentType){\n",
    "\n",
    "  n = length(body)\n",
    "  boundary = getBoundary(contentType)\n",
    " \n",
    "  bString = paste(\"--\", boundary, sep = \"\")\n",
    "  bStringLocs = which(bString == body)\n",
    "  eString = paste(\"--\", boundary, \"--\", sep = \"\")\n",
    "  eStringLoc = which(eString == body)\n",
    "  \n",
    "  if (length(eStringLoc) == 0) eStringLoc = n\n",
    "  if (length(bStringLocs) <= 1) {\n",
    "    attachLocs = NULL\n",
    "    msgLastLine = n\n",
    "    if (length(bStringLocs) == 0) bStringLocs = 0\n",
    "  } else {\n",
    "    attachLocs = c(bStringLocs[ -1 ],  eStringLoc)\n",
    "    msgLastLine = bStringLocs[2] - 1\n",
    "  }\n",
    "  \n",
    "  msg = body[ (bStringLocs[1] + 1) : msgLastLine] \n",
    "  if ( eStringLoc < n )\n",
    "    msg = c(msg, body[ (eStringLoc + 1) : n ])\n",
    "  \n",
    "  if ( !is.null(attachLocs) ) {\n",
    "    attachLens = diff(attachLocs, lag = 1) \n",
    "    attachTypes = mapply(function(begL, endL) {\n",
    "      CTloc = grep(\"^[Cc]ontent-[Tt]ype\", body[ (begL + 1) : (endL - 1)])\n",
    "      if ( length(CTloc) == 0 ) {\n",
    "        MIMEType = NA\n",
    "      } else {\n",
    "        CTval = body[ begL + CTloc[1] ]\n",
    "        CTval = gsub('\"', \"\", CTval )\n",
    "        MIMEType = sub(\" *[Cc]ontent-[Tt]ype: *([^;]*);?.*\", \"\\\\1\", CTval)   \n",
    "      }\n",
    "      return(MIMEType)\n",
    "    }, attachLocs[-length(attachLocs)], attachLocs[-1])\n",
    "  }\n",
    "  \n",
    "  if (is.null(attachLocs)) return(list(body = msg, attachDF = NULL) )\n",
    "  return(list(body = msg, \n",
    "             attachDF = data.frame(aLen = attachLens, \n",
    "                                     aType = unlist(attachTypes),\n",
    "                                     stringsAsFactors = FALSE)))                                \n",
    "}                       \n",
    "\n",
    "readEmail = function(dirName) {\n",
    "       # retrieve the names of files in directory\n",
    "  fileNames = list.files(dirName, full.names = TRUE)\n",
    "       # drop files that are not email\n",
    "  notEmail = grep(\"cmds$\", fileNames)\n",
    "  if ( length(notEmail) > 0) fileNames = fileNames[ - notEmail ]\n",
    "\n",
    "       # read all files in the directory\n",
    "  lapply(fileNames, readLines, encoding = \"latin1\")\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to process all of the emails\n",
    "processAllEmail = function(dirName, isSpam = FALSE)\n",
    "{\n",
    "       # read all files in the directory\n",
    "  messages = readEmail(dirName)\n",
    "  fileNames = names(messages)\n",
    "  n = length(messages)\n",
    "  \n",
    "       # split header from body\n",
    "  eSplit = lapply(messages, splitMessage)\n",
    "  rm(messages)\n",
    "\n",
    "       # process header as named character vector\n",
    "  headerList = lapply(eSplit, function(msg) \n",
    "                                 processHeader(msg$header))\n",
    "  \n",
    "       # extract content-type key\n",
    "  contentTypes = sapply(headerList, function(header) \n",
    "                                       header[\"Content-Type\"])\n",
    "  \n",
    "       # extract the body\n",
    "  bodyList = lapply(eSplit, function(msg) msg$body)\n",
    "  rm(eSplit)\n",
    "\n",
    "       # which email have attachments\n",
    "  hasAttach = grep(\"^ *multi\", tolower(contentTypes))\n",
    "\n",
    "       # get summary stats for attachments and the shorter body\n",
    "  attList = mapply(processAttach, bodyList[hasAttach], \n",
    "                   contentTypes[hasAttach], SIMPLIFY = FALSE)\n",
    "  \n",
    "  bodyList[hasAttach] = lapply(attList, function(attEl) \n",
    "                                           attEl$body)\n",
    " \n",
    "  attachInfo = vector(\"list\", length = n )\n",
    "  attachInfo[ hasAttach ] = lapply(attList, \n",
    "                                  function(attEl) attEl$attachDF)\n",
    " \n",
    "       # prepare return structure\n",
    "  emailList = mapply(function(header, body, attach, isSpam) {\n",
    "                       list(isSpam = isSpam, header = header, \n",
    "                            body = body, attach = attach)\n",
    "                     },\n",
    "                     headerList, bodyList, attachInfo, \n",
    "                     rep(isSpam, n), SIMPLIFY = FALSE )\n",
    "  names(emailList) = fileNames\n",
    "  \n",
    "  invisible(emailList)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = c(1:5, 15, 27, 68, 69, 329, 404, 427, 516, 852, 971)\n",
    "emailStruct = mapply(processAllEmail, fullDirNames,\n",
    "                     isSpam = rep( c(FALSE, TRUE), 3:2))      \n",
    "emailStruct = unlist(emailStruct, recursive = FALSE)\n",
    "\n",
    "sampleStruct = emailStruct[ indx ]\n",
    "\n",
    "save(emailStruct, file=\"emailXX.rda\")\n",
    "\n",
    "header = sampleStruct[[1]]$header\n",
    "subject = header[\"Subject\"]\n",
    "els = strsplit(subject, \"\")\n",
    "all(els %in% LETTERS)\n",
    "\n",
    "testSubject = c(\"DEAR MADAME\", \"WINNER!\", \"\")\n",
    "\n",
    "els = strsplit(testSubject, \"\")\n",
    "sapply(els, function(subject) all(subject %in% LETTERS))\n",
    "\n",
    "\n",
    "gsub(\"[[:punct:] ]\", \"\", testSubject)\n",
    "\n",
    "gsub(\"[^[:alpha:]]\", \"\", testSubject)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isYelling = function(msg) {\n",
    "#   if ( \"Subject\" %in% names(msg$header) ) {\n",
    "#      el = gsub(\"[^[:alpha:]]\", \"\", msg$header[\"Subject\"])\n",
    "#      if (nchar(el) > 0) \n",
    "#         nchar(gsub(\"[A-Z]\", \"\", el)) < 1\n",
    "#      else \n",
    "#         FALSE\n",
    "#   } else \n",
    "#     NA\n",
    "# }\n",
    "\n",
    "# perCaps =\n",
    "# function(msg)\n",
    "# {\n",
    "#   body = paste(msg$body, collapse = \"\")\n",
    "\n",
    "#        # Return NA if the body of the message is \"empty\"\n",
    "#   if(length(body) == 0 || nchar(body) == 0) return(NA)\n",
    "\n",
    "#        # Eliminate non-alpha characters\n",
    "#   body = gsub(\"[^[:alpha:]]\", \"\", body)\n",
    "#   capText = gsub(\"[^A-Z]\", \"\", body)\n",
    "#   100 * nchar(capText)/nchar(body)\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #sapply(sampleStruct, perCaps)\n",
    "# # function list\n",
    "# funcList = list( \n",
    "#  isRe = function(msg) {\n",
    "#        \"Subject\" %in% names(msg$header) &&\n",
    "#          length(grep(\"^[ \\t]*Re:\", msg$header[[\"Subject\"]])) > 0\n",
    "#   },\n",
    "#   numLines = function(msg) \n",
    "#                 length(msg$body),\n",
    "#   isYelling = function(msg) {\n",
    "#     if ( \"Subject\" %in% names(msg$header) ) {\n",
    "#        el = gsub(\"[^[:alpha:]]\", \"\", msg$header[\"Subject\"])\n",
    "#        if (nchar(el) > 0) \n",
    "#          nchar(gsub(\"[A-Z]\", \"\", el)) < 1\n",
    "#        else \n",
    "#          FALSE\n",
    "#     }\n",
    "#     else NA\n",
    "#   },\n",
    "#   perCaps = function(msg) {\n",
    "#     body = paste(msg$body, collapse = \"\")\n",
    "\n",
    "#          # Return NA if the body of the message is \"empty\"\n",
    "#     if(length(body) == 0 || nchar(body) == 0) return(NA)\n",
    "\n",
    "#          # Eliminate non-alpha characters\n",
    "#     body = gsub(\"[^[:alpha:]]\", \"\", body)\n",
    "#     capText = gsub(\"[^A-Z]\", \"\", body)\n",
    "#     100 * nchar(capText)/nchar(body)\n",
    "#   }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lapply(funcList, function(func) \n",
    "#                    sapply(sampleStruct, function(msg) func(msg)))\n",
    "\n",
    "createDerivedDF =\n",
    "function(email = emailStruct, operations = funcList, \n",
    "         verbose = FALSE)\n",
    "{\n",
    "  els = lapply(names(operations),\n",
    "               function(id) {\n",
    "                 if(verbose) print(id)\n",
    "                 e = operations[[id]]\n",
    "                 v = if(is.function(e)) \n",
    "                        sapply(email, e)\n",
    "                      else \n",
    "                        sapply(email, function(msg) eval(e))\n",
    "                 v\n",
    "         })\n",
    "\n",
    "   df = as.data.frame(els)\n",
    "   names(df) = names(operations)\n",
    "   invisible(df)\n",
    "}\n",
    "\n",
    "# sampleDF = createDerivedDF(sampleStruct)\n",
    "# head(sampleDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcList = list(\n",
    "  isSpam =\n",
    "    expression(msg$isSpam)\n",
    "  ,\n",
    "  isRe =\n",
    "    function(msg) {\n",
    "      # Can have a Fwd: Re:  ... but we are not looking for this here.\n",
    "      # We may want to look at In-Reply-To field.\n",
    "      \"Subject\" %in% names(msg$header) && \n",
    "        length(grep(\"^[ \\t]*Re:\", msg$header[[\"Subject\"]])) > 0\n",
    "    }\n",
    "  ,\n",
    "  numLines =\n",
    "    function(msg) length(msg$body)\n",
    "  ,\n",
    "  bodyCharCt =\n",
    "    function(msg)\n",
    "      sum(nchar(msg$body))\n",
    "  ,\n",
    "  underscore =\n",
    "    function(msg) {\n",
    "      if(!\"Reply-To\" %in% names(msg$header))\n",
    "        return(FALSE)\n",
    "      \n",
    "      txt <- msg$header[[\"Reply-To\"]]\n",
    "      length(grep(\"_\", txt)) > 0  && \n",
    "        length(grep(\"[0-9A-Za-z]+\", txt)) > 0\n",
    "    }\n",
    "  ,\n",
    "  subExcCt = \n",
    "    function(msg) {\n",
    "      x = msg$header[\"Subject\"]\n",
    "      if(length(x) == 0 || sum(nchar(x)) == 0 || is.na(x))\n",
    "        return(NA)\n",
    "      \n",
    "      sum(nchar(gsub(\"[^!]\",\"\", x)))\n",
    "    }\n",
    "  ,\n",
    "  subQuesCt =\n",
    "    function(msg) {\n",
    "      x = msg$header[\"Subject\"]\n",
    "      if(length(x) == 0 || sum(nchar(x)) == 0 || is.na(x))\n",
    "        return(NA)\n",
    "      \n",
    "      sum(nchar(gsub(\"[^?]\",\"\", x)))\n",
    "    }\n",
    "  ,\n",
    "  numAtt = \n",
    "    function(msg) {\n",
    "      if (is.null(msg$attach)) return(0)\n",
    "      else nrow(msg$attach)\n",
    "    }\n",
    "   \n",
    "  ,\n",
    "  priority =\n",
    "    function(msg) {\n",
    "      ans <- FALSE\n",
    "      # Look for names X-Priority, Priority, X-Msmail-Priority\n",
    "      # Look for high any where in the value\n",
    "      ind = grep(\"priority\", tolower(names(msg$header)))\n",
    "      if (length(ind) > 0)  {\n",
    "        ans <- length(grep(\"high\", tolower(msg$header[ind]))) >0\n",
    "      }\n",
    "      ans\n",
    "    }\n",
    "  ,\n",
    "  numRec =\n",
    "    function(msg) {\n",
    "      # unique or not.\n",
    "      els = getMessageRecipients(msg$header)\n",
    "      \n",
    "      if(length(els) == 0)\n",
    "        return(NA)\n",
    "      \n",
    "      # Split each line by \",\"  and in each of these elements, look for\n",
    "      # the @ sign. This handles\n",
    "      tmp = sapply(strsplit(els, \",\"), function(x) grep(\"@\", x))\n",
    "      sum(sapply(tmp, length))\n",
    "    }\n",
    "  ,\n",
    "  perCaps =\n",
    "    function(msg)\n",
    "    {\n",
    "      body = paste(msg$body, collapse = \"\")\n",
    "      \n",
    "      # Return NA if the body of the message is \"empty\"\n",
    "      if(length(body) == 0 || nchar(body) == 0) return(NA)\n",
    "      \n",
    "      # Eliminate non-alpha characters and empty lines \n",
    "      body = gsub(\"[^[:alpha:]]\", \"\", body)\n",
    "      els = unlist(strsplit(body, \"\"))\n",
    "      ctCap = sum(els %in% LETTERS)\n",
    "      100 * ctCap / length(els)\n",
    "    }\n",
    "  ,\n",
    "  isInReplyTo =\n",
    "    function(msg)\n",
    "    {\n",
    "      \"In-Reply-To\" %in% names(msg$header)\n",
    "    }\n",
    "  ,\n",
    "  sortedRec =\n",
    "    function(msg)\n",
    "    {\n",
    "      ids = getMessageRecipients(msg$header)\n",
    "      all(sort(ids) == ids)\n",
    "    }\n",
    "  ,\n",
    "  subPunc =\n",
    "    function(msg)\n",
    "    {\n",
    "      if(\"Subject\" %in% names(msg$header)) {\n",
    "        el = gsub(\"['/.:@-]\", \"\", msg$header[\"Subject\"])\n",
    "        length(grep(\"[A-Za-z][[:punct:]]+[A-Za-z]\", el)) > 0\n",
    "      }\n",
    "      else\n",
    "        FALSE\n",
    "    },\n",
    "  hour =\n",
    "    function(msg)\n",
    "    {\n",
    "      date = msg$header[\"Date\"]\n",
    "      if ( is.null(date) ) return(NA)\n",
    "      # Need to handle that there may be only one digit in the hour\n",
    "      locate = regexpr(\"[0-2]?[0-9]:[0-5][0-9]:[0-5][0-9]\", date)\n",
    "      \n",
    "      if (locate < 0)\n",
    "        locate = regexpr(\"[0-2]?[0-9]:[0-5][0-9]\", date)\n",
    "      if (locate < 0) return(NA)\n",
    "      \n",
    "      hour = substring(date, locate, locate+1)\n",
    "      hour = as.numeric(gsub(\":\", \"\", hour))\n",
    "      \n",
    "      locate = regexpr(\"PM\", date)\n",
    "      if (locate > 0) hour = hour + 12\n",
    "      \n",
    "      locate = regexpr(\"[+-][0-2][0-9]00\", date)\n",
    "      if (locate < 0) offset = 0\n",
    "      else offset = as.numeric(substring(date, locate, locate + 2))\n",
    "      (hour - offset) %% 24\n",
    "    }\n",
    "  ,\n",
    "  multipartText =\n",
    "    function(msg)\n",
    "    {\n",
    "      if (is.null(msg$attach)) return(FALSE)\n",
    "      numAtt = nrow(msg$attach)\n",
    "      \n",
    "      types = \n",
    "        length(grep(\"(html|plain|text)\", msg$attach$aType)) > (numAtt/2)\n",
    "    }\n",
    "  ,\n",
    "  hasImages =\n",
    "    function(msg)\n",
    "    {\n",
    "      if (is.null(msg$attach)) return(FALSE)\n",
    "      \n",
    "      length(grep(\"^ *image\", tolower(msg$attach$aType))) > 0\n",
    "    }\n",
    "  ,\n",
    "  isPGPsigned =\n",
    "    function(msg)\n",
    "    {\n",
    "      if (is.null(msg$attach)) return(FALSE)\n",
    "      \n",
    "      length(grep(\"pgp\", tolower(msg$attach$aType))) > 0\n",
    "    },\n",
    "  perHTML =\n",
    "    function(msg)\n",
    "    {\n",
    "      if(! (\"Content-Type\" %in% names(msg$header))) return(0)\n",
    "      \n",
    "      el = tolower(msg$header[\"Content-Type\"]) \n",
    "      if (length(grep(\"html\", el)) == 0) return(0)\n",
    "      \n",
    "      els = gsub(\"[[:space:]]\", \"\", msg$body)\n",
    "      totchar = sum(nchar(els))\n",
    "      totplain = sum(nchar(gsub(\"<[^<]+>\", \"\", els )))\n",
    "      100 * (totchar - totplain)/totchar\n",
    "    },\n",
    "  subSpamWords =\n",
    "    function(msg)\n",
    "    {\n",
    "      if(\"Subject\" %in% names(msg$header))\n",
    "        length(grep(paste(SpamCheckWords, collapse = \"|\"), \n",
    "                    tolower(msg$header[\"Subject\"]))) > 0\n",
    "      else\n",
    "        NA\n",
    "    }\n",
    "  ,\n",
    "  subBlanks =\n",
    "    function(msg)\n",
    "    {\n",
    "      if(\"Subject\" %in% names(msg$header)) {\n",
    "        x = msg$header[\"Subject\"]\n",
    "        # should we count blank subject line as 0 or 1 or NA?\n",
    "        if (nchar(x) == 1) return(0)\n",
    "        else 100 *(1 - (nchar(gsub(\"[[:blank:]]\", \"\", x))/nchar(x)))\n",
    "      } else NA\n",
    "    }\n",
    "  ,\n",
    "  noHost =\n",
    "    function(msg)\n",
    "    {\n",
    "      # Or use partial matching.\n",
    "      idx = pmatch(\"Message-\", names(msg$header))\n",
    "      \n",
    "      if(is.na(idx)) return(NA)\n",
    "      \n",
    "      tmp = msg$header[idx]\n",
    "      return(length(grep(\".*@[^[:space:]]+\", tmp)) ==  0)\n",
    "    }\n",
    "  ,\n",
    "  numEnd =\n",
    "    function(msg)\n",
    "    {\n",
    "      # If we just do a grep(\"[0-9]@\",  )\n",
    "      # we get matches on messages that have a From something like\n",
    "      # \" \\\"marty66@aol.com\\\" <synjan@ecis.com>\"\n",
    "      # and the marty66 is the \"user's name\" not the login\n",
    "      # So we can be more precise if we want.\n",
    "      x = names(msg$header)\n",
    "      if ( !( \"From\" %in% x) ) return(NA)\n",
    "      login = gsub(\"^.*<\", \"\", msg$header[\"From\"])\n",
    "      if ( is.null(login) ) \n",
    "        login = gsub(\"^.*<\", \"\", msg$header[\"X-From\"])\n",
    "      if ( is.null(login) ) return(NA)\n",
    "      login = strsplit(login, \"@\")[[1]][1]\n",
    "      length(grep(\"[0-9]+$\", login)) > 0\n",
    "    },\n",
    "  isYelling =\n",
    "    function(msg)\n",
    "    {\n",
    "      if ( \"Subject\" %in% names(msg$header) ) {\n",
    "        el = gsub(\"[^[:alpha:]]\", \"\", msg$header[\"Subject\"])\n",
    "        if (nchar(el) > 0) nchar(gsub(\"[A-Z]\", \"\", el)) < 1\n",
    "        else FALSE\n",
    "      }\n",
    "      else\n",
    "        NA\n",
    "    },\n",
    "  forwards =\n",
    "    function(msg)\n",
    "    {\n",
    "      x = msg$body\n",
    "      if(length(x) == 0 || sum(nchar(x)) == 0)\n",
    "        return(NA)\n",
    "      \n",
    "      ans = length(grep(\"^[[:space:]]*>\", x))\n",
    "      100 * ans / length(x)\n",
    "    },\n",
    "  isOrigMsg =\n",
    "    function(msg)\n",
    "    {\n",
    "      x = msg$body\n",
    "      if(length(x) == 0) return(NA)\n",
    "      \n",
    "      length(grep(\"^[^[:alpha:]]*original[^[:alpha:]]+message[^[:alpha:]]*$\", \n",
    "                  tolower(x) ) ) > 0\n",
    "    },\n",
    "  isDear =\n",
    "    function(msg)\n",
    "    {\n",
    "      x = msg$body\n",
    "      if(length(x) == 0) return(NA)\n",
    "      \n",
    "      length(grep(\"^[[:blank:]]*dear +(sir|madam)\\\\>\", \n",
    "                  tolower(x))) > 0\n",
    "    },\n",
    "  isWrote =\n",
    "    function(msg)\n",
    "    {\n",
    "      x = msg$body\n",
    "      if(length(x) == 0) return(NA)\n",
    "      \n",
    "      length(grep(\"(wrote|schrieb|ecrit|escribe):\", tolower(x) )) > 0\n",
    "    },\n",
    "  avgWordLen =\n",
    "    function(msg)\n",
    "    {\n",
    "      txt = paste(msg$body, collapse = \" \")\n",
    "      if(length(txt) == 0 || sum(nchar(txt)) == 0) return(0)\n",
    "      \n",
    "      txt = gsub(\"[^[:alpha:]]\", \" \", txt)\n",
    "      words = unlist(strsplit(txt, \"[[:blank:]]+\"))\n",
    "      wordLens = nchar(words)\n",
    "      mean(wordLens[ wordLens > 0 ])\n",
    "    }\n",
    "  ,\n",
    "  numDlr =\n",
    "    function(msg)\n",
    "    {\n",
    "      x = paste(msg$body, collapse = \"\")\n",
    "      if(length(x) == 0 || sum(nchar(x)) == 0)\n",
    "        return(NA)\n",
    "      \n",
    "      nchar(gsub(\"[^$]\",\"\", x))\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpamCheckWords =\n",
    "  c(\"viagra\", \"pounds\", \"free\", \"weight\", \"guarantee\", \"million\", \n",
    "    \"dollars\", \"credit\", \"risk\", \"prescription\", \"generic\", \"drug\",\n",
    "    \"financial\", \"save\", \"dollar\", \"erotic\", \"million\", \"barrister\",\n",
    "    \"beneficiary\", \"easy\", \n",
    "    \"money back\", \"money\", \"credit card\")\n",
    "\n",
    "\n",
    "getMessageRecipients =\n",
    "  function(header)\n",
    "  {\n",
    "    c(if(\"To\" %in% names(header))  header[[\"To\"]] else character(0),\n",
    "      if(\"Cc\" %in% names(header))  header[[\"Cc\"]] else character(0),\n",
    "      if(\"Bcc\" %in% names(header)) header[[\"Bcc\"]] else character(0)\n",
    "    )\n",
    "  }\n",
    "\n",
    "emailDF = createDerivedDF(emailStruct)\n",
    "dim(emailDF)\n",
    "#save(emailDF, file = \"spamAssassinDerivedDF.rda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load(\"Data/spamAssassinDerivedDF.rda\")\n",
    "#dim(emailDF)\n",
    "\n",
    "perCaps2 =\n",
    "function(msg)\n",
    "{\n",
    "  body = paste(msg$body, collapse = \"\")\n",
    "\n",
    "       # Return NA if the body of the message is \"empty\"\n",
    "  if(length(body) == 0 || nchar(body) == 0) return(NA)\n",
    "\n",
    "       # Eliminate non-alpha characters and empty lines \n",
    "  body = gsub(\"[^[:alpha:]]\", \"\", body)\n",
    "  els = unlist(strsplit(body, \"\"))\n",
    "  ctCap = sum(els %in% LETTERS)\n",
    "  100 * ctCap / length(els)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pC = sapply(emailStruct, perCaps)\n",
    "# pC2 = sapply(emailStruct, perCaps2)\n",
    "# identical(pC, pC2)\n",
    "\n",
    "# indNA = which(is.na(emailDF$subExcCt))\n",
    "\n",
    "# indNoSubject = which(sapply(emailStruct, \n",
    "#                             function(msg) \n",
    "#                               !(\"Subject\" %in% names(msg$header))))\n",
    "\n",
    "# all(indNA == indNoSubject)\n",
    "\n",
    "# all(emailDF$bodyCharCt > emailDF$numLines)\n",
    "\n",
    "\n",
    "# x.at = c(1,10,100,1000,10000,100000)\n",
    "# y.at = c(1, 5, 10, 50, 100, 500, 5000)\n",
    "# nL = 1 + emailDF$numLines\n",
    "# nC = 1 + emailDF$bodyCharCt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.at = c(1,10,100,1000,10000,100000)\n",
    "y.at = c(1, 5, 10, 50, 100, 500, 5000)\n",
    "nL = 1 + emailDF$numLines\n",
    "nC = 1 + emailDF$bodyCharCt\n",
    "\n",
    "\n",
    "#pdf(\"ScatterPlotNumLinesNumChars.pdf\", width = 6, height = 4.5)\n",
    "plot(nL ~ nC, log = \"xy\", pch=\".\", xlim=c(1,100000), axes = FALSE,\n",
    "     xlab = \"Number of Characters\", ylab = \"Number of Lines\")\n",
    "box() \n",
    "axis(1, at = x.at, labels = formatC(x.at, digits = 0, format=\"d\"))\n",
    "axis(2, at = y.at, labels = formatC(y.at, digits = 0, format=\"d\")) \n",
    "abline(a=0, b=1, col=\"red\", lwd = 2)\n",
    "dev.off()\n",
    "\n",
    "#pdf(\"SPAM_boxplotsPercentCaps.pdf\", width = 5, height = 5)\n",
    "\n",
    "percent = emailDF$perCaps\n",
    "isSpamLabs = factor(emailDF$isSpam, labels = c(\"ham\", \"spam\"))\n",
    "boxplot(log(1 + percent) ~ isSpamLabs,\n",
    "        main = \"Figure 3. Comparison of Two Measures of Length for a Message.\",\n",
    "        ylab = \"Percent Capitals (log)\")\n",
    "\n",
    "dev.copy(png,'Figure_3_SPAM_boxplotsPercentCaps.png')\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logPerCapsSpam = log(1 + emailDF$perCaps[ emailDF$isSpam ])\n",
    "logPerCapsHam = log(1 + emailDF$perCaps[ !emailDF$isSpam ])\n",
    "\n",
    "qqplot(logPerCapsSpam, logPerCapsHam, \n",
    "       xlab = \"Regular Email\", ylab = \"Spam Email\", \n",
    "       main = \"Figure 4. Percentage of Capital Letters (log scale)\",\n",
    "       pch = 19, cex = 0.3)     \n",
    "dev.copy(png,'Figure_4_SPAM_Percentage of Capital Letters.png')\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf(\"SPAM_scatterplotPercentCapsTotChars.pdf\", width = 8, height = 6)\n",
    " \n",
    "colI = c(\"#4DAF4A80\", \"#984EA380\")\n",
    "logBodyCharCt = log(1 + emailDF$bodyCharCt)\n",
    "logPerCaps = log(1 + emailDF$perCaps)\n",
    "plot(logPerCaps ~ logBodyCharCt, xlab = \"Total Characters (log)\",\n",
    "     ylab = \"Percent Capitals (log)\",\n",
    "     col = colI[1 + emailDF$isSpam],\n",
    "     main = \"Figure 5. Comparison of the Amount of Capitalization and the Size of the Message.\",\n",
    "     xlim = c(2,12), pch = 19, cex = 0.5)\n",
    "\n",
    "dev.copy(png,'Figure_5_SPAM_scatterplotPercentCapsTotChars.png')\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(emailDF$numAtt, isSpamLabs)\n",
    "#pdf(\"SPAM_mosaicPlots.pdf\", width = 8, height = 4)\n",
    "\n",
    "oldPar = par(mfrow = c(1, 2), mar = c(1,1,1,1))\n",
    "\n",
    "colM = c(\"#E41A1C80\", \"#377EB880\")\n",
    "isRe = factor(emailDF$isRe, labels = c(\"no Re:\", \"Re:\"))\n",
    "mosaicplot(table(isSpamLabs, isRe), main = \"\",\n",
    "           xlab = \"\", ylab = \"\", color = colM)\n",
    "\n",
    "fromNE = factor(emailDF$numEnd, labels = c(\"No #\", \"#\"))\n",
    "mosaicplot(table(isSpamLabs, fromNE), color = colM,\n",
    "           main = \"\", xlab=\"\", ylab = \"\")\n",
    "oldpar.title = 'Figure 6. Exploring Categorical Measures Derived from email.'\n",
    "par(oldPar)\n",
    "\n",
    "\n",
    "dev.copy(png,'Figure_6_SPAM_mosaicPlots.png')\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "setupRpart = function(data) {\n",
    "  logicalVars = which(sapply(data, is.logical))\n",
    "  facVars = lapply(data[ , logicalVars], \n",
    "                   function(x) {\n",
    "                      x = as.factor(x)\n",
    "                      levels(x) = c(\"F\", \"T\")\n",
    "                      x\n",
    "                   })\n",
    "  cbind(facVars, data[ , - logicalVars])\n",
    "}\n",
    "\n",
    "emailDFrp = setupRpart(emailDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "set.seed(418910)\n",
    "testSpamIdx = sample(numSpam, size = floor(numSpam/3))\n",
    "testHamIdx = sample(numHam, size = floor(numHam/3))\n",
    "\n",
    "testDF = \n",
    "  rbind( emailDFrp[ emailDFrp$isSpam == \"T\", ][testSpamIdx, ],\n",
    "         emailDFrp[emailDFrp$isSpam == \"F\", ][testHamIdx, ] )\n",
    "trainDF =\n",
    "  rbind( emailDFrp[emailDFrp$isSpam == \"T\", ][-testSpamIdx, ], \n",
    "         emailDFrp[emailDFrp$isSpam == \"F\", ][-testHamIdx, ])\n",
    "\n",
    "minsplit = 20\n",
    "rpartFit1 = rpart(isSpam ~ ., data = trainDF, method = \"class\")\n",
    "rpartFit1.5 = rpart(isSpam ~ ., data = trainDF, method = \"class\",minsplit = 2,   minbucket = 1) \n",
    "rpartFit2 = rpart(isSpam ~ ., data = trainDF, method = \"class\", parms = list(prior = c(.65,.35), split = \"information\"))\n",
    "rpartFit3 = rpart(isSpam ~ ., data = trainDF, method = \"class\",control = rpart.control(cp = 0.01,xval = 10))\n",
    "rpartFit4 = rpart(isSpam ~ ., data = trainDF, method = \"class\",control = rpart.control(cp = 0.01, minbucket = round(minsplit/3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to fit the given model\n",
    "rpartFitFunc = function(rpartFit,fileNamePostfix) {\n",
    "    print(rpartFit)\n",
    "    prp(rpartFit, extra = 1)\n",
    "\n",
    "    #library(rpart)\n",
    "    #pdf(\"SPAM_rpartTree.pdf\", width = 7, height = 7)\n",
    "\n",
    "    prp(rpartFit, extra = 1)\n",
    "    \n",
    "    fileName = paste('SPAM__rpartTree',fileNamePostfix,'.png',sep=\"\")\n",
    "    dev.copy(png,fileName)\n",
    "    dev.off()\n",
    "\n",
    "    predictions = predict(rpartFit, \n",
    "           newdata = testDF[, names(testDF) != \"isSpam\"],\n",
    "           type = \"class\")\n",
    "\n",
    "    predsForHam = predictions[ testDF$isSpam == \"F\" ]\n",
    "    summary(predsForHam)\n",
    "\n",
    "    sum(predsForHam == \"T\") / length(predsForHam)\n",
    "\n",
    "    predsForSpam = predictions[ testDF$isSpam == \"T\" ]\n",
    "    sum(predsForSpam == \"F\") / length(predsForSpam)\n",
    "\n",
    "    complexityVals = c(seq(0.00001, 0.0001, length=19),\n",
    "                       seq(0.0001, 0.001, length=19), \n",
    "                       seq(0.001, 0.005, length=9),\n",
    "                       seq(0.005, 0.01, length=9))\n",
    "    \n",
    "    fits = lapply(complexityVals, function(x) {\n",
    "         rpartObj = rpart(isSpam ~ ., data = trainDF,\n",
    "                          method=\"class\", \n",
    "                          control = rpart.control(cp=x) )\n",
    "           \n",
    "         predict(rpartObj, \n",
    "                 newdata = testDF[ , names(testDF) != \"isSpam\"],\n",
    "                 type = \"class\")\n",
    "        })\n",
    "\n",
    "    spam = testDF$isSpam == \"T\"\n",
    "    numSpam = sum(spam)\n",
    "    numHam = sum(!spam)\n",
    "    errs = sapply(fits, function(preds) {\n",
    "                          typeI = sum(preds[ !spam ] == \"T\") / numHam\n",
    "                          typeII = sum(preds[ spam ] == \"F\") / numSpam\n",
    "                          c(typeI = typeI, typeII = typeII)\n",
    "                         })\n",
    "    \n",
    "    #pdf(\"SPAM_rpartTypeIandII.pdf\", width = 8, height = 7)\n",
    "    #library(RColorBrewer)\n",
    "    cols = brewer.pal(9, \"Set1\")[c(3, 4, 5)]\n",
    "    plot(errs[1,] ~ complexityVals, type=\"l\", col=cols[2], \n",
    "         lwd = 2, ylim = c(0,0.2), xlim = c(0,0.01), \n",
    "         ylab=\"Error\", xlab=\"complexity parameter values\")\n",
    "    points(errs[2,] ~ complexityVals, type=\"l\", col=cols[1], lwd = 2)\n",
    "\n",
    "    text(x =c(0.003, 0.0035), y = c(0.12, 0.05), \n",
    "         labels=c(\"Type II Error\", \"Type I Error\"))\n",
    "\n",
    "    minI = which(errs[1,] == min(errs[1,]))[1]\n",
    "    abline(v = complexityVals[minI], col =\"grey\", lty =3, lwd=2)\n",
    "\n",
    "    text(0.0007, errs[1, minI]+0.01, \n",
    "         formatC(errs[1, minI], digits = 2))\n",
    "    text(0.0007, errs[2, minI]+0.01, \n",
    "         formatC(errs[2, minI], digits = 3))\n",
    "\n",
    " \n",
    "    fileName = paste('SPAM_rpartTypeIandII',fileNamePostfix,'.png',sep=\"\")\n",
    "    dev.copy(png,fileName)\n",
    "    dev.off()\n",
    "    return(complexityVals)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Regular model\n",
    "complexityVals1 = rpartFitFunc(rpartFit1,'_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Regular model\n",
    "complexityVals1.5 = rpartFitFunc(rpartFit1.5,'_1.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "complexityVals2 = rpartFitFunc(rpartFit2,'2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "complexityVals3 = rpartFitFunc(rpartFit3,'_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "complexityVals4 = rpartFitFunc(rpartFit4,'_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(emailDFrp,file=\"data.Rda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Factoize Logical Variables'.  \n",
    "We need to change it to numbers.  And as it turns out, there are quite a few NANs as well.  Let's set those to zero because imputation was 9 weeks ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "setupRnum = function(data) {\n",
    "  logicalVars = which(sapply(data, is.logical))\n",
    "  facVars = lapply(data[ , logicalVars], \n",
    "                   function(x) {\n",
    "                      x = as.numeric(x)\n",
    "                   })\n",
    "  cbind(facVars, data[ , - logicalVars])\n",
    "}\n",
    "\n",
    "emailDFnum = setupRnum(emailDF)\n",
    "\n",
    "emailDFnum[is.na(emailDFnum)]<-0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally Metric Stuff\n",
    "Because our authors prefer Type I/II errors, but the cool kids know that precision/recall/F1 is where its at, while the default of caret is accuracy and kappa.  To get us all on the same page, I create a function that returns the metrics we want.  However, rather than re-invent the wheel, I just install a package.  I am not sure if it had Type I/II errors so those I made my self.  \\#MLSwag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library(MLmetrics)\n",
    "f1 <- function(data, lev = NULL, model = NULL) {\n",
    "  f1_val <- F1_Score(y_pred = data$pred, y_true = data$obs, positive = lev[1])\n",
    "  p <- Precision(y_pred = data$pred, y_true = data$obs, positive = lev[1])\n",
    "  r <- Recall(y_pred = data$pred, y_true = data$obs, positive = lev[1])\n",
    "  fp <-sum(data$pred==0 & data$obs==1)/length(data$pred)  \n",
    " \n",
    "  fn <-sum(data$pred==1 & data$obs==0)/length(data$pred)\n",
    "    c(F1 = f1_val,\n",
    "    prec = p,\n",
    "    rec = r,\n",
    "    Type_I_err=fp,\n",
    "    Type_II_err=fn\n",
    "   )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok so lets get the naive bayes packages installed. (first 2 lines)\n",
    "The next line makes a dataframe of all the parameters to check.  \n",
    "If you don't know what they are, look them up\n",
    "https://topepo.github.io/caret/available-models.html\n",
    "\n",
    "Then we create a trainControl object.  It tells caret how to train--using a cross-validation ('cv') with 3 folds in this case (number = 3).  We want the final predictions of the best model and our summary is the custom function from above.\n",
    "\n",
    "Then we create our model: \"model_nb\".  We user the caret::train method.  We make 'isSpam' a factor because R is dumb and can't figure out that 1 and 0 are classes.  \n",
    "*as.factor(isSpam) ~ .*  means Y=as.factor(isSpam), X=everything else.\n",
    "    \n",
    "*method* is the package we are using, and we pass our tuning grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library(naivebayes)\n",
    "#library(e1071)\n",
    "nb_grid<-expand.grid(laplace=c(0,0.1,0.3,0.5,1), usekernel=c(T,F), adjust=c(T,F))\n",
    "train_control<-trainControl(method=\"cv\", number=3, savePredictions = 'final',summaryFunction = f1)\n",
    "model_nb<-caret::train(as.factor(isSpam) ~ .,data=emailDFnum, trControl = train_control, method='naive_bayes',tuneGrid = nb_grid)\n",
    "model_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Did the boss fool us with the folds?  Nope.\n",
    "table(model_nb$pred['Resample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val<-seq(from = 0, to=0.01, by=0.0005)\n",
    "#library(rpart)\n",
    "cart_grid<-expand.grid(cp=val)\n",
    "train_control<-trainControl(method=\"cv\", number =5, savePredictions = 'final',summaryFunction = f1)\n",
    "model_rpart<-caret::train(as.factor(isSpam) ~ .,data=emailDFnum, trControl = train_control, method='rpart',tuneGrid = cart_grid)\n",
    "model_rpart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library(randomForest)\n",
    "rf_grid<-expand.grid(mtry=seq(from =1, to = 25, by = 2))\n",
    "train_control<-trainControl(method=\"cv\", number=3, savePredictions = 'final',summaryFunction = f1)\n",
    "model_rf<-caret::train(as.factor(isSpam) ~ .,data=emailDFnum, trControl = train_control, ntree=200,method='rf',tuneGrid = rf_grid)\n",
    "model_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#library(xgboost)\n",
    "xgb_grid<-expand.grid(nrounds = 100, max_depth = c(3,5,7,9,11), eta = c(0.01,0.03,0.1), gamma=c(1,3,5,10), colsample_bytree=1, min_child_weight=1, subsample=1)\n",
    "train_control<-trainControl(method=\"cv\", number=3, savePredictions = 'final',summaryFunction = f1)\n",
    "model_xgb<-caret::train(as.factor(isSpam) ~ .,data=emailDFnum, trControl = train_control,method='xgbTree',tuneGrid = xgb_grid)\n",
    "model_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
